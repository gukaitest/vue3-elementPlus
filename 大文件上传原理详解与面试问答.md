# 大文件上传原理详解与面试问答

本文档详细分析大文件上传的前后端实现逻辑、性能优化原理，以及面试中常见的问题与解答。

## 目录

1. [概述](#概述)
2. [前端实现详解](#前端实现详解)
3. [后端实现详解](#后端实现详解)
4. [核心优化原理](#核心优化原理)
5. [完整上传流程](#完整上传流程)
6. [面试问题与解答](#面试问题与解答)
7. [最佳实践建议](#最佳实践建议)

---

## 概述

大文件上传是指处理超过浏览器或服务器限制的文件上传场景。传统的一次性上传方式存在以下问题：

- **超时问题**：大文件上传时间长，容易导致请求超时
- **内存占用**：一次性加载整个文件到内存，占用大量资源
- **网络不稳定**：网络中断需要重新上传整个文件
- **用户体验差**：无法显示上传进度，无法暂停/继续

本实现通过**分片上传**、**断点续传**、**秒传**等技术，解决了上述问题。

---

## 前端实现详解

### 1. 文件切片（File Chunking）

#### 1.1 切片大小配置

```typescript
// 切片大小：1MB
const chunkSize = 1 * 1024 * 1024; // 1MB in bytes
```

**为什么选择 1MB？**

- ✅ **平衡性能**：太小会增加请求次数，太大可能导致单次请求超时
- ✅ **内存友好**：1MB 切片不会占用过多内存
- ✅ **网络友好**：适合大多数网络环境

#### 1.2 文件切片实现

文件切片在 Web Worker 中完成（`hash-worker.js`）：

```javascript
function createFileChunk(file, chunkSize) {
  const fileChunkList = [];
  let cur = 0;
  while (cur < file.size) {
    // 使用 Blob.slice() 方法创建切片
    fileChunkList.push({ 
      chunkFile: file.slice(cur, cur + chunkSize) 
    });
    cur += chunkSize;
  }
  return fileChunkList;
}
```

**关键点**：

- 使用 `Blob.slice()` 方法，不会复制数据，只是创建引用
- 按固定大小切片，最后一个切片可能小于 `chunkSize`
- 切片顺序从 0 开始编号

### 2. 文件 Hash 计算

#### 2.1 为什么需要 Hash？

- **唯一标识**：通过 Hash 值唯一标识文件
- **秒传功能**：检查服务器是否已存在相同文件
- **断点续传**：识别已上传的切片
- **文件完整性**：验证文件是否被篡改

#### 2.2 Web Worker 计算 Hash

```typescript
const useWorker = (file: File): Promise<WorkerResult> => {
  return new Promise(resolve => {
    const worker = new Worker(
      new URL('@/worker/hash-worker.js', import.meta.url),
      { type: 'module' }
    );
    worker.postMessage({ file, chunkSize });
    worker.onmessage = e => {
      const { fileHash, fileChunkList } = e.data;
      if (fileHash) {
        resolve({ fileHash, fileChunkList });
      }
    };
  });
};
```

**为什么使用 Web Worker？**

- ✅ **不阻塞主线程**：Hash 计算是 CPU 密集型操作，在 Worker 中执行不会阻塞 UI
- ✅ **用户体验好**：主线程可以继续响应用户操作
- ✅ **性能优化**：充分利用多核 CPU

#### 2.3 Hash 计算流程

```javascript
// hash-worker.js
async function calculateChunksHash(fileChunkList) {
  const spark = new SparkMD5.ArrayBuffer();
  
  async function loadNext(index) {
    if (index >= fileChunkList.length) {
      return spark.end(); // 返回最终 MD5
    }
    
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.readAsArrayBuffer(fileChunkList[index].chunkFile);
      reader.onload = e => {
        spark.append(e.target.result); // 追加到 MD5 计算
        resolve(loadNext(index + 1)); // 递归处理下一个切片
      };
    });
  }
  
  const fileHash = await loadNext(0);
  return fileHash;
}
```

**计算原理**：

1. 使用 SparkMD5 库计算文件的 MD5 值
2. 逐个读取切片，追加到 MD5 计算器
3. 所有切片处理完成后，返回最终 Hash 值

### 3. 文件验证（秒传功能）

#### 3.1 秒传原理

在上传前检查服务器是否已存在该文件：

```typescript
const res = await checkFile({
  fileHash: `${fileHash}${baseName}`,
  fileName: file.name
});

if (!res.data.shouldUpload) {
  // 文件已存在，实现秒传
  finishTask(inTaskArrItem);
  return;
}
```

**秒传条件**：

- 服务器已存在完整的文件
- 文件的 Hash 值相同
- 直接标记为上传完成，无需上传

#### 3.2 断点续传

如果文件不存在，但部分切片已上传：

```typescript
const { shouldUpload, uploadedList } = res.data;

if (uploadedList.length > 0) {
  // 过滤掉已上传的切片
  inTaskArrItem.allChunkList = inTaskArrItem.allChunkList.filter(
    chunk => !uploadedList.includes(chunk.chunkHash)
  );
}
```

**断点续传流程**：

1. 服务器返回已上传的切片列表
2. 前端过滤掉已上传的切片
3. 只上传未上传的切片
4. 所有切片上传完成后，调用合并接口

### 4. 并发控制

#### 4.1 动态并发数计算

```typescript
// 实时动态获取并发请求数
const isTaskArrIng = uploadFileList.value.filter(
  item => item.state === 1 || item.state === 2
);

// 浏览器同域名同一时间请求的最大并发数限制为 6
// 例如如果有 3 个文件同时上传，则每个文件切片接口最多调 6 / 3 == 2 个
maxRequest.value = Math.ceil(6 / isTaskArrIng.length);
```

**并发控制原理**：

- 浏览器对同一域名的并发请求有限制（通常为 6 个）
- 多个文件同时上传时，需要分配并发数
- 动态计算每个文件的最大并发数

#### 4.2 切片上传队列

```typescript
const uploadSignleFile = (taskArrItem: FileUploadStatus) => {
  // 从数组末尾提取 maxRequest 个元素
  const whileRequest = taskArrItem.allChunkList.slice(-maxRequest.value);
  
  // 设置正在请求中的个数
  taskArrItem.whileRequests.push(...whileRequest);
  
  // 从待上传列表中移除
  if (taskArrItem.allChunkList.length > maxRequest.value) {
    taskArrItem.allChunkList.splice(-maxRequest.value);
  } else {
    taskArrItem.allChunkList = [];
  }
  
  // 并发上传
  for (const item of whileRequest) {
    uploadChunk(item);
  }
};
```

**队列管理**：

- `allChunkList`：待上传的切片列表
- `whileRequests`：正在上传的切片列表
- 每次从待上传列表取出 `maxRequest` 个切片并发上传

### 5. 单个切片上传

#### 5.1 上传请求

```typescript
const uploadChunk = async (needObj: FileChunk) => {
  const fd = new FormData();
  fd.append('fileHash', fileHash);
  fd.append('fileName', fileName);
  fd.append('index', String(index));
  fd.append('chunkFile', chunkFile);
  fd.append('chunkHash', chunkHash);
  fd.append('chunkSize', String(chunkSize));
  fd.append('chunkNumber', String(chunkNumber));
  
  const res = await uploadFile(fd, (onCancelFunc: () => void) => {
    needObj.cancel = onCancelFunc; // 保存取消函数
  });
  
  // 处理响应...
};
```

#### 5.2 错误重试机制

```typescript
if (!res || res.response.data.code !== '0000') {
  taskArrItem.errNumber += 1;
  
  if (taskArrItem.errNumber > 3) {
    // 错误超过 3 次，暂停上传
    pauseUpload(taskArrItem, false);
    return false;
  }
  
  // 重试上传
  return uploadChunk(needObj);
}
```

**重试策略**：

- 单次上传失败，自动重试
- 错误次数超过 3 次，暂停上传
- 防止无限重试导致资源浪费

#### 5.3 上传成功处理

```typescript
if (res.response.data.code === '0000') {
  taskArrItem.finishNumber += 1;
  needObj.finish = true;
  signleFileProgress(needObj, taskArrItem); // 更新进度
  
  // 移除正在上传列表
  taskArrItem.whileRequests = taskArrItem.whileRequests.filter(
    item => item.chunkFile !== needObj.chunkFile
  );
  
  // 检查是否所有切片都已上传完成
  if (taskArrItem.finishNumber === chunkNumber) {
    handleMerge(taskArrItem); // 调用合并接口
  } else {
    uploadSignleFile(taskArrItem); // 继续上传下一个切片
  }
}
```

### 6. 进度更新

#### 6.1 进度计算

```typescript
const signleFileProgress = (needObj: FileChunk, taskArrItem: FileUploadStatus) => {
  // 已完成切片数 / 总切片数 * 100
  taskArrItem.percentage = Number(
    ((taskArrItem.finishNumber / needObj.chunkNumber) * 100).toFixed(2)
  );
};
```

**进度计算原理**：

- 每个切片上传完成后，更新已完成数量
- 进度 = 已完成切片数 / 总切片数 × 100%
- 保留两位小数，提供精确的进度显示

### 7. 暂停/继续/取消功能

#### 7.1 暂停上传

```typescript
const pauseUpload = (taskArrItem: FileUploadStatus, elsePause = true) => {
  if (![4, 6].includes(taskArrItem.state)) {
    taskArrItem.state = elsePause ? 3 : 5; // 3=暂停，5=中断
  }
  
  // 取消正在请求中的所有接口
  if (taskArrItem.whileRequests.length > 0) {
    for (const itemB of taskArrItem.whileRequests) {
      if (itemB.cancel) {
        itemB.cancel(); // 调用 AbortController.abort()
      }
    }
  }
};
```

**暂停原理**：

- 使用 `AbortController` 取消正在进行的请求
- 将状态设置为暂停（3）或中断（5）
- 已上传的切片保留，下次可以继续上传

#### 7.2 继续上传

```typescript
const resumeUpload = (taskArrItem: FileUploadStatus) => {
  taskArrItem.state = 2; // 设置为上传中
  
  // 把暂停时正在上传的切片放回待上传列表
  taskArrItem.allChunkList.push(...taskArrItem.whileRequests);
  taskArrItem.whileRequests = [];
  
  // 继续上传
  uploadSignleFile(taskArrItem);
};
```

**继续上传原理**：

- 将暂停时正在上传的切片放回待上传列表
- 重新开始上传流程
- 已上传的切片不会重复上传（通过断点续传实现）

#### 7.3 取消上传

```typescript
const cancelSingle = async (taskArrItem: FileUploadStatus) => {
  pauseUpload(taskArrItem); // 暂停上传
  // 从列表中删除
  uploadFileList.value = uploadFileList.value.filter(
    item => item.fileHash !== taskArrItem.fileHash
  );
};
```

### 8. 文件状态管理

```typescript
interface FileUploadStatus {
  state: 0 | 1 | 2 | 3 | 4 | 5 | 6;
  // 0: 什么都不做
  // 1: 文件处理中（计算 Hash）
  // 2: 上传中
  // 3: 暂停
  // 4: 上传完成
  // 5: 上传中断
  // 6: 上传失败
}
```

---

## 后端实现详解

### 1. 切片上传接口

#### 1.1 接口实现

```javascript
exports.uploadChunk = async (req, res) => {
  try {
    const form = new multiparty.Form();
    form.parse(req, async (err, fields, files) => {
      if (err) {
        res.send({ code: -1, msg: '单片上传失败', data: err });
        return;
      }
      
      const { fileHash, chunkHash, fileName } = fields;
      const { chunkFile } = files;
      
      // 创建临时文件目录
      const chunkCache = getChunkDir(fileHash);
      if (!fse.existsSync(chunkCache)) {
        await fse.mkdirs(chunkCache);
      }
      
      // 将切片移动到临时目录
      await fse.move(chunkFile[0].path, `${chunkCache}/${chunkHash}`, {
        overwrite: true,
      });
      
      res.send({
        code: '0000',
        msg: '单片上传完成',
        data: { fileHash, chunkHash, fileName },
      });
    });
  } catch (errB) {
    res.send({ code: -1, msg: '单片上传失败', data: errB });
  }
};
```

**关键点**：

- 使用 `multiparty` 解析 FormData
- 每个文件的切片存储在独立目录：`target/chunkCache_${fileHash}/`
- 切片文件名使用 `chunkHash`（格式：`${fileHash}-${index}`）

#### 1.2 目录结构

```
target/
  ├── chunkCache_fileHash1/
  │   ├── fileHash1-0
  │   ├── fileHash1-1
  │   └── fileHash1-2
  ├── chunkCache_fileHash2/
  │   ├── fileHash2-0
  │   └── fileHash2-1
  └── fileHash1.jpg (合并后的文件)
```

### 2. 文件验证接口

#### 2.1 接口实现

```javascript
exports.verify = async (req, res) => {
  try {
    const { fileHash, fileName } = req.body;
    
    const ext = extractExt(fileName);
    const filePath = path.resolve(UPLOAD_DIR, `${fileHash}${ext}`);
    
    // 如果文件已存在，实现秒传
    if (fse.existsSync(filePath)) {
      res.send({
        code: '0000',
        data: {
          shouldUpload: false,
          uploadedList: [],
        },
        msg: '已存在该文件',
      });
    } else {
      // 返回已上传的切片列表（断点续传）
      res.json({
        code: '0000',
        data: {
          shouldUpload: true,
          uploadedList: await createUploadedList(fileHash),
        },
        msg: '需要上传文件/部分切片',
      });
    }
  } catch (err) {
    res.send({ code: -1, msg: '上传失败', data: err });
  }
};
```

#### 2.2 获取已上传切片列表

```javascript
const createUploadedList = async (fileHash) => {
  const chunkCache = getChunkDir(fileHash);
  return fse.existsSync(chunkCache)
    ? await fse.readdir(chunkCache)
    : [];
};
```

**验证流程**：

1. 检查完整文件是否存在 → 秒传
2. 检查切片目录是否存在 → 断点续传
3. 返回已上传的切片列表

### 3. 合并切片接口

#### 3.1 接口实现

```javascript
exports.mergeChunks = async (req, res) => {
  try {
    const { chunkSize, fileName, fileHash } = req.body;
    const ext = extractExt(fileName);
    const filePath = path.resolve(UPLOAD_DIR, `${fileHash}${ext}`);
    
    // 合并切片
    await mergeFileChunk(chunkSize, fileHash, filePath);
    
    res.send({
      code: '0000',
      msg: '文件合并成功',
    });
  } catch (e) {
    res.send({
      code: -1,
      data: e,
      msg: '文件合并失败！',
    });
  }
};
```

#### 3.2 合并逻辑

```javascript
const mergeFileChunk = async (chunkSize, fileHash, filePath) => {
  const chunkCache = getChunkDir(fileHash);
  const chunkPaths = await fse.readdir(chunkCache);
  
  // 根据切片下标排序
  chunkPaths.sort((a, b) => a.split('-')[1] - b.split('-')[1]);
  
  let promiseList = [];
  for (let index = 0; index < chunkPaths.length; index++) {
    let chunkPath = path.resolve(chunkCache, chunkPaths[index]);
    // 在指定位置创建可写流
    let writeStream = fse.createWriteStream(filePath, {
      start: index * chunkSize, // 关键：指定写入位置
    });
    promiseList.push(pipeStream(chunkPath, writeStream));
  }
  
  // 等待所有切片写入完成
  await Promise.all(promiseList);
  
  // 删除临时切片目录
  if (fse.pathExistsSync(chunkCache)) {
    fse.remove(chunkCache);
  }
};
```

#### 3.3 流式写入

```javascript
const pipeStream = (path, writeStream) => {
  return new Promise((resolve) => {
    const readStream = fse.createReadStream(path);
    readStream.pipe(writeStream).on('finish', () => {
      fse.unlinkSync(path); // 删除切片文件
      resolve();
    });
  });
};
```

**合并原理**：

1. 读取所有切片文件
2. 按索引排序
3. 使用 `createWriteStream` 的 `start` 选项，在指定位置写入
4. 并发写入所有切片（使用 `Promise.all`）
5. 写入完成后删除切片文件

**为什么可以并发写入？**

- 每个切片写入的位置不同（`start: index * chunkSize`）
- 文件系统支持在指定位置写入
- 不会相互覆盖

---

## 核心优化原理

### 1. 分片上传

**原理**：

- 将大文件分割成多个小切片（如 1MB）
- 逐个上传切片，而不是一次性上传整个文件

**优势**：

- ✅ **避免超时**：单个切片上传时间短，不易超时
- ✅ **内存友好**：不需要将整个文件加载到内存
- ✅ **进度可控**：可以精确显示上传进度
- ✅ **错误恢复**：单个切片失败只需重传该切片

### 2. 并发控制

**原理**：

- 限制同时上传的切片数量
- 根据浏览器并发限制动态调整

**优势**：

- ✅ **充分利用带宽**：多个切片并发上传，提高速度
- ✅ **避免请求过多**：控制并发数，避免服务器压力过大
- ✅ **动态调整**：根据文件数量动态分配并发数

### 3. 断点续传

**原理**：

- 上传前检查服务器已存在的切片
- 只上传未上传的切片

**优势**：

- ✅ **节省带宽**：已上传的切片不重复上传
- ✅ **提高效率**：网络中断后可以继续上传
- ✅ **用户体验好**：支持暂停/继续功能

### 4. 秒传功能

**原理**：

- 通过文件 Hash 值检查服务器是否已存在相同文件
- 如果存在，直接标记为上传完成

**优势**：

- ✅ **极速上传**：相同文件无需上传，瞬间完成
- ✅ **节省存储**：相同文件只存储一份
- ✅ **节省带宽**：不占用上传带宽

### 5. Web Worker 计算 Hash

**原理**：

- 在 Web Worker 线程中计算文件 Hash
- 不阻塞主线程

**优势**：

- ✅ **不阻塞 UI**：主线程可以继续响应用户操作
- ✅ **性能优化**：充分利用多核 CPU
- ✅ **用户体验好**：界面不会卡顿

### 6. 错误重试机制

**原理**：

- 单次上传失败自动重试
- 错误次数超过阈值后暂停上传

**优势**：

- ✅ **提高成功率**：网络波动时自动重试
- ✅ **避免无限重试**：超过阈值后停止，避免资源浪费

---

## 完整上传流程

### 流程图

```
用户选择文件
    ↓
检查文件大小（限制 100MB）
    ↓
创建上传任务（state = 0）
    ↓
开始处理（state = 1）
    ↓
Web Worker 计算文件 Hash
    ↓
调用 checkFile 接口
    ↓
    ├─→ 文件已存在 → 秒传完成（state = 4）
    │
    └─→ 文件不存在
        ↓
        获取已上传切片列表（断点续传）
        ↓
        过滤已上传的切片
        ↓
        开始上传（state = 2）
        ↓
        并发上传切片（最多 6 个并发）
        ↓
        更新进度条
        ↓
        所有切片上传完成？
        │
        ├─→ 否 → 继续上传下一个切片
        │
        └─→ 是 → 调用 mergeChunks 接口
            ↓
            服务器合并切片
            ↓
            上传完成（state = 4）
```

### 关键步骤详解

#### 1. 文件选择与验证

```typescript
const handleUploadFile = async (e: Event) => {
  const fileEle = e.target as HTMLInputElement;
  const files = fileEle.files;
  
  // 检查文件大小
  const oversizedFiles = Array.from(files).filter(
    file => file.size > MAX_FILE_SIZE
  );
  if (oversizedFiles.length > 0) {
    ElMessage.error(`文件大小超过限制：${MAX_FILE_SIZE_MB}MB`);
    return;
  }
  
  // 处理每个文件...
};
```

#### 2. Hash 计算

```typescript
// 在 Web Worker 中计算
const { fileHash, fileChunkList } = await useWorker(file);
```

#### 3. 文件验证

```typescript
const res = await checkFile({
  fileHash: `${fileHash}${baseName}`,
  fileName: file.name
});

if (!res.data.shouldUpload) {
  // 秒传
  finishTask(inTaskArrItem);
  return;
}
```

#### 4. 切片上传

```typescript
// 过滤已上传的切片
inTaskArrItem.allChunkList = fileChunkList
  .filter(chunk => !uploadedList.includes(chunk.chunkHash));

// 开始上传
uploadSignleFile(inTaskArrItem);
```

#### 5. 合并切片

```typescript
if (taskArrItem.finishNumber === chunkNumber) {
  await handleMerge(taskArrItem);
}
```

---

## 面试问题与解答

### Q1: 为什么需要分片上传？分片大小如何选择？

**答案**：

**为什么需要分片上传**：

1. **避免超时**：大文件上传时间长，容易导致请求超时
2. **内存友好**：不需要将整个文件加载到内存
3. **进度可控**：可以精确显示上传进度
4. **错误恢复**：单个切片失败只需重传该切片
5. **并发上传**：多个切片并发上传，提高速度

**分片大小选择**：

- **太小**（< 100KB）：请求次数过多，增加服务器压力
- **太大**（> 5MB）：单次请求时间长，容易超时
- **推荐**：1-2MB，平衡性能和稳定性

```typescript
// 本实现使用 1MB
const chunkSize = 1 * 1024 * 1024; // 1MB
```

### Q2: 如何实现断点续传？

**答案**：

**实现步骤**：

1. **上传前检查**：调用验证接口，获取已上传的切片列表
2. **过滤切片**：前端过滤掉已上传的切片
3. **继续上传**：只上传未上传的切片

**前端实现**：

```typescript
// 1. 调用验证接口
const res = await checkFile({ fileHash, fileName });
const { uploadedList } = res.data;

// 2. 过滤已上传的切片
allChunkList = allChunkList.filter(
  chunk => !uploadedList.includes(chunk.chunkHash)
);

// 3. 继续上传未上传的切片
uploadSignleFile(taskArrItem);
```

**后端实现**：

```javascript
// 返回已上传的切片列表
const createUploadedList = async (fileHash) => {
  const chunkCache = getChunkDir(fileHash);
  return fse.existsSync(chunkCache)
    ? await fse.readdir(chunkCache)
    : [];
};
```

### Q3: 如何实现秒传功能？

**答案**：

**实现原理**：

1. **计算文件 Hash**：使用 MD5 或 SHA256 计算文件唯一标识
2. **上传前检查**：调用验证接口，检查服务器是否已存在该文件
3. **秒传处理**：如果文件已存在，直接标记为上传完成

**实现代码**：

```typescript
// 1. 计算文件 Hash（在 Web Worker 中）
const { fileHash } = await useWorker(file);

// 2. 检查服务器
const res = await checkFile({ fileHash, fileName });

// 3. 如果文件已存在，实现秒传
if (!res.data.shouldUpload) {
  finishTask(inTaskArrItem); // 直接标记为完成
  console.log('文件已存在，实现秒传');
  return;
}
```

**后端检查**：

```javascript
const filePath = path.resolve(UPLOAD_DIR, `${fileHash}${ext}`);
if (fse.existsSync(filePath)) {
  res.send({
    code: '0000',
    data: { shouldUpload: false },
    msg: '已存在该文件',
  });
}
```

### Q4: 如何控制并发数？为什么需要控制并发？

**答案**：

**为什么需要控制并发**：

1. **浏览器限制**：浏览器对同一域名的并发请求有限制（通常为 6 个）
2. **服务器压力**：过多并发请求会增加服务器压力
3. **网络带宽**：过多并发可能占用过多带宽，影响其他请求

**如何控制并发**：

```typescript
// 1. 动态计算并发数
const isTaskArrIng = uploadFileList.value.filter(
  item => item.state === 1 || item.state === 2
);
maxRequest.value = Math.ceil(6 / isTaskArrIng.length);

// 2. 从队列中取出指定数量的切片
const whileRequest = taskArrItem.allChunkList.slice(-maxRequest.value);

// 3. 并发上传
for (const item of whileRequest) {
  uploadChunk(item);
}
```

**并发控制策略**：

- **固定并发**：每个文件固定并发数（如 3 个）
- **动态并发**：根据文件数量动态调整（本实现）
- **优先级队列**：重要文件优先上传

### Q5: 如何保证文件完整性？

**答案**：

**完整性保证措施**：

1. **Hash 验证**：上传前后计算 Hash，确保文件未被篡改
2. **切片顺序**：合并时按索引排序，确保顺序正确
3. **切片数量验证**：检查所有切片是否都已上传
4. **合并验证**：合并后验证文件大小和 Hash

**实现代码**：

```typescript
// 1. 上传前计算 Hash
const { fileHash } = await useWorker(file);

// 2. 检查所有切片是否都已上传
if (taskArrItem.finishNumber === chunkNumber) {
  await handleMerge(taskArrItem);
}

// 3. 后端合并时按索引排序
chunkPaths.sort((a, b) => a.split('-')[1] - b.split('-')[1]);
```

### Q6: 如何处理上传失败？重试机制如何实现？

**答案**：

**失败处理策略**：

1. **单次失败重试**：单个切片上传失败，自动重试
2. **错误次数限制**：超过阈值后暂停上传，避免无限重试
3. **用户提示**：失败后提示用户，支持手动重试

**实现代码**：

```typescript
const uploadChunk = async (needObj: FileChunk) => {
  try {
    const res = await uploadFile(fd, onCancel);
    
    if (!res || res.response.data.code !== '0000') {
      taskArrItem.errNumber += 1;
      
      // 错误超过 3 次，暂停上传
      if (taskArrItem.errNumber > 3) {
        pauseUpload(taskArrItem, false);
        return false;
      }
      
      // 重试上传
      return uploadChunk(needObj);
    }
    
    // 成功处理...
  } catch (error) {
    console.error('切片上传请求异常', error);
    return false;
  }
};
```

**重试策略优化**：

- **指数退避**：重试间隔逐渐增加（1s、2s、4s...）
- **随机抖动**：避免同时重试导致服务器压力过大
- **最大重试次数**：限制重试次数，避免无限重试

### Q7: 为什么使用 Web Worker 计算 Hash？有什么优势？

**答案**：

**为什么使用 Web Worker**：

1. **Hash 计算是 CPU 密集型操作**：计算大文件的 Hash 需要大量 CPU 资源
2. **不阻塞主线程**：在主线程计算会导致页面卡顿
3. **用户体验**：Worker 中计算不影响用户操作

**优势**：

- ✅ **不阻塞 UI**：主线程可以继续响应用户操作
- ✅ **性能优化**：充分利用多核 CPU
- ✅ **用户体验好**：界面不会卡顿
- ✅ **可扩展**：可以处理更大的文件

**实现代码**：

```typescript
const useWorker = (file: File): Promise<WorkerResult> => {
  return new Promise(resolve => {
    const worker = new Worker(
      new URL('@/worker/hash-worker.js', import.meta.url),
      { type: 'module' }
    );
    worker.postMessage({ file, chunkSize });
    worker.onmessage = e => {
      const { fileHash, fileChunkList } = e.data;
      if (fileHash) {
        resolve({ fileHash, fileChunkList });
      }
    };
  });
};
```

### Q8: 如何实现暂停/继续功能？

**答案**：

**暂停实现**：

```typescript
const pauseUpload = (taskArrItem: FileUploadStatus) => {
  taskArrItem.state = 3; // 设置为暂停状态
  
  // 取消正在进行的请求
  if (taskArrItem.whileRequests.length > 0) {
    for (const item of taskArrItem.whileRequests) {
      if (item.cancel) {
        item.cancel(); // 调用 AbortController.abort()
      }
    }
  }
};
```

**继续实现**：

```typescript
const resumeUpload = (taskArrItem: FileUploadStatus) => {
  taskArrItem.state = 2; // 设置为上传中
  
  // 把暂停时正在上传的切片放回待上传列表
  taskArrItem.allChunkList.push(...taskArrItem.whileRequests);
  taskArrItem.whileRequests = [];
  
  // 继续上传
  uploadSignleFile(taskArrItem);
};
```

**取消请求实现**：

```typescript
export function uploadFile(data: any, onCancel: any) {
  const controller = new AbortController();
  const signal = controller.signal;
  
  const requestUpload = request({
    url: 'upload/upload',
    method: 'post',
    data,
    signal
  });
  
  if (typeof onCancel === 'function') {
    onCancel(() => controller.abort()); // 传递取消函数
  }
  
  return requestUpload;
}
```

### Q9: 后端如何合并切片？为什么可以并发写入？

**答案**：

**合并实现**：

```javascript
const mergeFileChunk = async (chunkSize, fileHash, filePath) => {
  const chunkCache = getChunkDir(fileHash);
  const chunkPaths = await fse.readdir(chunkCache);
  
  // 按索引排序
  chunkPaths.sort((a, b) => a.split('-')[1] - b.split('-')[1]);
  
  let promiseList = [];
  for (let index = 0; index < chunkPaths.length; index++) {
    let chunkPath = path.resolve(chunkCache, chunkPaths[index]);
    // 在指定位置创建可写流
    let writeStream = fse.createWriteStream(filePath, {
      start: index * chunkSize, // 关键：指定写入位置
    });
    promiseList.push(pipeStream(chunkPath, writeStream));
  }
  
  // 并发写入所有切片
  await Promise.all(promiseList);
};
```

**为什么可以并发写入**：

1. **指定写入位置**：使用 `createWriteStream` 的 `start` 选项，在指定位置写入
2. **不相互覆盖**：每个切片写入的位置不同（`start: index * chunkSize`）
3. **文件系统支持**：文件系统支持在指定位置写入，不会相互覆盖

**流式写入**：

```javascript
const pipeStream = (path, writeStream) => {
  return new Promise((resolve) => {
    const readStream = fse.createReadStream(path);
    readStream.pipe(writeStream).on('finish', () => {
      fse.unlinkSync(path); // 删除切片文件
      resolve();
    });
  });
};
```

### Q10: 如何优化大文件上传的性能？

**答案**：

**性能优化措施**：

1. **分片上传**：将大文件分割成小切片，提高上传效率
2. **并发控制**：多个切片并发上传，充分利用带宽
3. **断点续传**：网络中断后可以继续上传，避免重复上传
4. **秒传功能**：相同文件无需上传，瞬间完成
5. **Web Worker**：Hash 计算不阻塞主线程
6. **流式处理**：使用流式读写，减少内存占用
7. **压缩传输**：上传前压缩文件（如果适用）
8. **CDN 加速**：使用 CDN 加速上传

**具体优化**：

```typescript
// 1. 动态并发数
maxRequest.value = Math.ceil(6 / isTaskArrIng.length);

// 2. 错误重试机制
if (taskArrItem.errNumber > 3) {
  pauseUpload(taskArrItem, false);
}

// 3. 进度更新优化（防抖）
const debounceUpdateProgress = debounce(updateProgress, 100);
```

### Q11: 如何保证上传的安全性？

**答案**：

**安全措施**：

1. **文件类型验证**：限制上传的文件类型
2. **文件大小限制**：限制上传的文件大小
3. **Hash 验证**：验证文件完整性，防止文件被篡改
4. **权限验证**：上传前验证用户权限
5. **病毒扫描**：上传后扫描文件（服务器端）
6. **存储隔离**：上传的文件存储在隔离目录
7. **HTTPS 传输**：使用 HTTPS 加密传输

**实现代码**：

```typescript
// 1. 文件大小限制
const MAX_FILE_SIZE = 100 * 1024 * 1024; // 100MB
if (file.size > MAX_FILE_SIZE) {
  ElMessage.error(`文件大小超过限制：${MAX_FILE_SIZE_MB}MB`);
  return;
}

// 2. 文件类型验证（可根据需求添加）
const allowedTypes = ['image/jpeg', 'image/png', 'application/pdf'];
if (!allowedTypes.includes(file.type)) {
  ElMessage.error('不支持的文件类型');
  return;
}
```

### Q12: 如何处理多文件同时上传？

**答案**：

**处理策略**：

1. **任务队列**：为每个文件创建独立的上传任务
2. **并发控制**：根据文件数量动态分配并发数
3. **状态管理**：每个文件独立的状态管理
4. **进度显示**：每个文件独立的进度条

**实现代码**：

```typescript
// 1. 为每个文件创建独立任务
Array.from(files).forEach(async (file, i) => {
  const inTaskArrItem = reactive<FileUploadStatus>({
    id: `${new Date().getTime()}${i}`,
    state: 0,
    fileHash: '',
    fileName: file.name,
    // ...
  });
  
  uploadFileList.value.push(inTaskArrItem);
  
  // 开始上传
  await handleUploadFile(file, inTaskArrItem);
});

// 2. 动态计算并发数
const isTaskArrIng = uploadFileList.value.filter(
  item => item.state === 1 || item.state === 2
);
maxRequest.value = Math.ceil(6 / isTaskArrIng.length);
```

---

## 最佳实践建议

### 1. 切片大小选择

- **小文件**（< 10MB）：可以不分片，直接上传
- **中等文件**（10-100MB）：1-2MB 切片
- **大文件**（> 100MB）：2-5MB 切片

### 2. 并发数控制

- **单文件上传**：3-6 个并发
- **多文件上传**：动态分配，确保总并发不超过浏览器限制

### 3. 错误处理

- **重试机制**：单次失败自动重试，最多 3 次
- **用户提示**：失败后明确提示用户，支持手动重试
- **日志记录**：记录上传日志，便于问题排查

### 4. 进度显示

- **精确进度**：显示精确的上传进度（百分比）
- **速度显示**：显示上传速度（MB/s）
- **时间估算**：显示预计剩余时间

### 5. 性能优化

- **Web Worker**：Hash 计算在 Worker 中执行
- **流式处理**：使用流式读写，减少内存占用
- **CDN 加速**：使用 CDN 加速上传

### 6. 安全性

- **文件验证**：验证文件类型和大小
- **权限控制**：上传前验证用户权限
- **HTTPS 传输**：使用 HTTPS 加密传输

---

## 总结

大文件上传是一个复杂的系统，涉及前端切片、Hash 计算、并发控制、断点续传、秒传等多个技术点。通过合理的设计和优化，可以实现高效、稳定、用户友好的大文件上传功能。

**核心技术点**：

1. ✅ **分片上传**：将大文件分割成小切片
2. ✅ **并发控制**：动态控制并发数，充分利用带宽
3. ✅ **断点续传**：网络中断后可以继续上传
4. ✅ **秒传功能**：相同文件无需上传
5. ✅ **Web Worker**：Hash 计算不阻塞主线程
6. ✅ **错误重试**：自动重试机制，提高成功率
7. ✅ **暂停/继续**：支持用户控制上传过程

通过掌握这些技术点，可以在面试中自信地回答相关问题，并在实际项目中实现高效的大文件上传功能。

